{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demonstrated-directive",
   "metadata": {},
   "source": [
    "### Manually evaluating model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "political-greece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from common.trainers.bert_glue_trainer import BertGLUETrainer\n",
    "from data.bert_processors.processors import *\n",
    "from common.evaluators.bert_glue_evaluator import BertGLUEEvaluator\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "from data.h5_processors.h5_processors import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "wrong-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self, \n",
    "                 max_seq_length = 128, \n",
    "                 num_labels = 2, \n",
    "                 model = 'RTE',\n",
    "                 checkpoint = 'bert-base-uncased'):\n",
    "        if 'base' in checkpoint and 'QQP' in model:\n",
    "            self.state = r\"C:\\w266\\data2\\checkpoints\\BERT-qqpairs_epoch_1.pt\"\n",
    "        elif 'base' in checkpoint:\n",
    "            self.state = \"C:\\w266\\data\\embed_checkpoints\\%s_epoch_1.pt\" %model\n",
    "        else:\n",
    "            self.state = \"C:\\w266\\data\\embed_checkpoints\\\\bert_large\\%s_epoch_1.pt\" %model\n",
    "            #self.state = r\"C:\\BERTVision\\code\\torch\\model_checkpoints\\bert-large-uncased\\CoLA\\2021-03-28_17-41-17.pt\"\n",
    "        self.batch_size = 16\n",
    "        self.num_workers = 0\n",
    "        self.n_gpu = 1\n",
    "        \n",
    "        if num_labels > 1:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            self.criterion = nn.MSELoss()\n",
    "        self.checkpoint = checkpoint\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.num_labels = num_labels\n",
    "        self.model = model\n",
    "        self.error = False\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "self = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "usual-smile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "self.checkpoint = 'bert-base-uncased'\n",
    "model = BertForSequenceClassification.from_pretrained(self.checkpoint,\n",
    "                                                       num_labels=self.num_labels,\n",
    "                                                       output_hidden_states=True).to('cuda')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "diverse-primary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_r = BertForSequenceClassification.from_pretrained(self.checkpoint,\n",
    "                                                       num_labels=1,\n",
    "                                                       output_hidden_states=True).to('cuda')\n",
    "model_r.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "corporate-small",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_3 = BertForSequenceClassification.from_pretrained(self.checkpoint,\n",
    "                                                       num_labels=3,\n",
    "                                                       output_hidden_states=True).to('cuda')\n",
    "model_3.load_state_dict(torch.load(\"C:\\w266\\data\\embed_checkpoints\\\\bert_large\\%s_epoch_1.pt\" %\"MNLI\"))\n",
    "model_3.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "local-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(processor, **kwargs):\n",
    "    self = Args(**kwargs)\n",
    "    \n",
    "    if kwargs['model'] == 'STSB':\n",
    "        m = model_r\n",
    "    else:\n",
    "        m = model\n",
    "    \n",
    "    m.load_state_dict(torch.load(self.state))\n",
    "    return BertGLUEEvaluator(m, \n",
    "                             processor, \n",
    "                             self, \n",
    "                             logger,\n",
    "                             standalone_eval = True).get_loss(type='dev')\n",
    "\n",
    "def evaluate_mnli(processor, **kwargs):\n",
    "    self = Args(**kwargs)\n",
    "    \n",
    "    m = model_3\n",
    "    \n",
    "    #m.load_state_dict(torch.load(self.state))\n",
    "    return (BertGLUEEvaluator(m, \n",
    "                             processor, \n",
    "                             self, \n",
    "                             logger,\n",
    "                             standalone_eval = True).get_loss(type='dev_matched'),\n",
    "            BertGLUEEvaluator(m, \n",
    "                             processor, \n",
    "                             self, \n",
    "                             logger,\n",
    "                             standalone_eval = True).get_loss(type='dev_mismatched'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "russian-spokesman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 21:50:19.696 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8622907880795017, 0.8618186687172965, 0.5767521862971022)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bert large for STSB\n",
    "kwarg = kwargs[6]\n",
    "evaluate_results(kwarg[0], **kwarg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "undefined-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 21:52:49.584 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:04<00:00, 21.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8735816166189053, 0.8685228797436788, 0.5343236320830406)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bert base for STSB\n",
    "kwarg = kwargs[6]\n",
    "kwarg[1]['checkpoint'] = 'bert-base-uncased'\n",
    "evaluate_results(kwarg[0], **kwarg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "former-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 20:30:13.357 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 22.39it/s]\n",
      "2021-03-28 20:30:16.866 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [00:05<00:00, 20.80it/s]\n",
      "b'Skipping line 660: expected 4 fields, saw 5\\n'\n",
      "2021-03-28 20:30:22.662 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 330/330 [00:16<00:00, 20.14it/s]\n",
      "2021-03-28 20:30:39.708 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2527/2527 [01:58<00:00, 21.33it/s]\n",
      "2021-03-28 20:32:38.788 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:01<00:00, 11.79it/s]\n",
      "2021-03-28 20:32:40.867 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 21.83it/s]\n",
      "2021-03-28 20:32:43.932 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:04<00:00, 21.35it/s]\n"
     ]
    }
   ],
   "source": [
    "#bert-base\n",
    "results = {}\n",
    "kwargs = [(CoLA, {'model': 'CoLA', 'max_seq_length' : 128}),\n",
    "          (MSR, {'model': 'MSR', 'max_seq_length' : 128}),\n",
    "          (QNLI, {'model': 'QNLI', 'max_seq_length' : 128}),\n",
    "          (QQP, {'model': 'QQP', 'max_seq_length' : 128}),\n",
    "          (RTE, {'model': 'RTE', 'max_seq_length' : 250}),\n",
    "          (SST, {'model': 'SST', 'max_seq_length' : 128}),\n",
    "          (STSB, {'model': 'STSB', 'max_seq_length' : 128, 'num_labels': 1}),\n",
    "          #(MNLI, {'model': 'MNLI', 'max_seq_length' : 128})\n",
    "         ]\n",
    "\n",
    "for kwarg in kwargs:\n",
    "    results[kwarg[1]['model']] = evaluate_results(kwarg[0], **kwarg[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "first-preserve",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 20:32:49.038 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:29<00:00, 21.01it/s]\n",
      "2021-03-28 20:33:18.517 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 615/615 [00:29<00:00, 20.99it/s]\n"
     ]
    }
   ],
   "source": [
    "matched, mismatched = evaluate_mnli(MNLI, **{'model': 'MNLI', 'max_seq_length' : 128})\n",
    "results['MNLI_matched'] = matched[0]\n",
    "results['MNLI_mismatched'] = mismatched[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "original-sigma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLA 0.5336603793351659\n",
      "MSR 0.8202898550724638\n",
      "QNLI 0.9018230155715914\n",
      "QQP 0.8962156814246847\n",
      "RTE 0.6389891696750902\n",
      "SST 0.926605504587156\n",
      "STSB 0.8735816171329647\n",
      "MNLI_matched 0.8231278655119715\n",
      "MNLI_mismatched 0.8327908868999186\n"
     ]
    }
   ],
   "source": [
    "#bert-base\n",
    "for i in results:\n",
    "    print(i, results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "tough-roommate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 20:40:40.860 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:08<00:00,  7.80it/s]\n",
      "2021-03-28 20:40:51.237 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [00:14<00:00,  7.51it/s]\n",
      "b'Skipping line 660: expected 4 fields, saw 5\\n'\n",
      "2021-03-28 20:41:07.017 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 330/330 [00:44<00:00,  7.47it/s]\n",
      "2021-03-28 20:42:02.063 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2527/2527 [05:36<00:00,  7.50it/s]\n",
      "2021-03-28 20:47:50.484 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:04<00:00,  3.85it/s]\n",
      "2021-03-28 20:48:06.155 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:07<00:00,  7.65it/s]\n",
      "2021-03-28 20:48:25.430 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#bert-large\n",
    "#bert-base\n",
    "results2 = {}\n",
    "kwargs = [(CoLA, {'model': 'CoLA', 'max_seq_length' : 128}),\n",
    "          (MSR, {'model': 'MSR', 'max_seq_length' : 128}),\n",
    "          (QNLI, {'model': 'QNLI', 'max_seq_length' : 128}),\n",
    "          (QQP, {'model': 'QQP', 'max_seq_length' : 128}),\n",
    "          (RTE, {'model': 'RTE', 'max_seq_length' : 250}),\n",
    "          (SST, {'model': 'SST', 'max_seq_length' : 128}),\n",
    "          (STSB, {'model': 'STSB', 'max_seq_length' : 128, 'num_labels': 1}),\n",
    "          #(MNLI, {'model': 'MNLI', 'max_seq_length' : 128})\n",
    "         ]\n",
    "\n",
    "for kwarg in kwargs:\n",
    "    kwarg[1]['checkpoint'] = 'bert-large-uncased'\n",
    "    results2[kwarg[1]['model']] = evaluate_results(kwarg[0], **kwarg[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "corresponding-guitar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 20:52:30.081 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [01:21<00:00,  7.52it/s]\n",
      "2021-03-28 20:53:52.060 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 615/615 [01:22<00:00,  7.47it/s]\n"
     ]
    }
   ],
   "source": [
    "matched, mismatched = evaluate_mnli(MNLI, **{'model': 'MNLI', 'max_seq_length' : 128})\n",
    "results2['MNLI_matched'] = matched[0]\n",
    "results2['MNLI_mismatched'] = mismatched[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "distinguished-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLA 0.20666007059005728\n",
      "MSR 0.7634782608695653\n",
      "QNLI 0.9073300417774401\n",
      "QQP 0.8962651496413554\n",
      "RTE 0.5306859205776173\n",
      "SST 0.9288990825688074\n",
      "STSB 0.862290788524249\n",
      "MNLI_matched 0.8518593988792664\n",
      "MNLI_mismatched 0.8513018714401953\n"
     ]
    }
   ],
   "source": [
    "#bert-large\n",
    "for i in results2:\n",
    "    print(i, results2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-yeast",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "catholic-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Args(model = 'CoLA', checkpoint = 'bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ahead-sheriff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(self.checkpoint,\n",
    "                                                       num_labels=self.num_labels,\n",
    "                                                       output_hidden_states=True).to('cuda')\n",
    "model.load_state_dict(torch.load(self.state))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "approved-cradle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 18:17:09.886 | INFO     | common.evaluators.bert_glue_evaluator:get_loss:88 - Generating metrics\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 58/58 [00:08<00:00,  6.80it/s]\n"
     ]
    }
   ],
   "source": [
    "results = BertGLUEEvaluator(model, \n",
    "                             CoLA, \n",
    "                             self, \n",
    "                             logger,\n",
    "                             standalone_eval = True).get_loss(type='dev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "weekly-senator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20666007059005728, 0.5573520136290583)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-discretion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
