{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Activation, Convolution2D, Conv2D, LocallyConnected2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Dense, Dropout, Input, concatenate\n",
    "from tensorflow.keras.layers import add, Add, ZeroPadding2D, GlobalMaxPooling2D, DepthwiseConv2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/w266/cris/BERTVision')\n",
    "\n",
    "from utils.model_zoo import *\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[1], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (131911, 1, 1024, 26), Dev shape: (12227, 1, 1024, 26)\n"
     ]
    }
   ],
   "source": [
    "with open('./data/train_embeddings_3_epoch.pkl', 'rb') as handle:\n",
    "#with open('./data/train_embeddings_1_epoch.pkl', 'rb') as handle:\n",
    "#with open('./data/train_embeddings_2_tenths_epochs.pkl', 'rb') as handle:\n",
    "    train = pickle.load(handle)\n",
    "    train = np.expand_dims(train, axis=1)\n",
    "\n",
    "with open('./data/dev_embeddings_3_epoch.pkl', 'rb') as handle:\n",
    "#with open('./data/dev_embeddings_1_epoch.pkl', 'rb') as handle:\n",
    "#with open('./data/dev_embeddings_2_tenths_epochs.pkl', 'rb') as handle:\n",
    "    dev = pickle.load(handle)\n",
    "    dev = np.expand_dims(dev, axis=1)\n",
    "\n",
    "print(f\"Train shape: {train.shape}, Dev shape: {dev.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = h5py.File(r'C:/w266/cris/BERTVision/data/squad_train.h5', 'r')\n",
    "\n",
    "indices = np.array(eval(open('indices.txt', 'r').readline()))\n",
    "\n",
    "train_input_start = np.array(train_data['input_start'], dtype = np.int32)[indices]\n",
    "train_input_end = np.array(train_data['input_end'], dtype = np.int32)[indices]\n",
    "\n",
    "answer_no_answer = np.where(train_input_start + train_input_end > 0, 0, 1)\n",
    "answer_no_answer = to_categorical(answer_no_answer).astype(np.uint8)\n",
    "\n",
    "with open('./data/dev_answers.pkl', 'rb') as handle:\n",
    "    dev_answers = pickle.load(handle)\n",
    "with open('./data/dev_qasids.pkl', 'rb') as handle:\n",
    "    dev_qasids = pickle.load(handle)\n",
    "\n",
    "del train_data, indices, train_input_start, train_input_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model <font color=\"Red\">Tiny Tenney Linear</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BinaryClassification_Adapter_Tenney\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 1, 1024, 26)]     0         \n",
      "_________________________________________________________________\n",
      "bert_concat (BertConcat)     (None, 1, 1024)           27        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorF [(None, 1024)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 2,077\n",
      "Trainable params: 2,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_tiny_tenney(input_shape = (1, 1024, 26), gpu_device = \"/gpu:1\"):\n",
    "    \n",
    "    with tf.device(gpu_device):\n",
    "        inp = layers.Input(input_shape, name = 'input_layer')\n",
    "        X = BertConcat() (inp)\n",
    "        X = tf.squeeze(X, axis = 1)\n",
    "        X = layers.Dense(2)(X)\n",
    "        model = Model(inputs = inp, outputs = X, name = 'BinaryClassification_Adapter_Tenney')\n",
    "\n",
    "    return model\n",
    "\n",
    "model_eval = get_tiny_tenney()\n",
    "model_eval.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model <font color=\"red\">AdapterPooling Tenney</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BinaryClassification_Adapter_Tenney\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        [(None, 1, 1024, 26) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_concat_32 (BertConcat)     (None, 1, 1024)      27          input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_expand_dims_25 (Ten [(None, 1, 1024, 1)] 0           bert_concat_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "adapter_pooler_25 (AdapterPoole (None, 1, 386, 1)    395650      tf_op_layer_expand_dims_25[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_25 (TensorF [(None, 1, 386)]     0           adapter_pooler_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_27 (T [(None, 1, 1024)]    0           input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_13 (TensorFl [(None, 1, 1410)]    0           tf_op_layer_Reshape_25[0][0]     \n",
      "                                                                 tf_op_layer_strided_slice_27[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_29 (TensorF [(None, 1410)]       0           tf_op_layer_concat_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 2)            2822        tf_op_layer_Squeeze_29[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 398,499\n",
      "Trainable params: 398,499\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_adapter_shared_skip_tenney_first(input_shape = (1, 1024, 26), gpu_device = \"/gpu:1\"):\n",
    "    \n",
    "    with tf.device(gpu_device):\n",
    "        inp = layers.Input(input_shape, name = 'input_layer')\n",
    "        inp_seq = inp[:,:,:,-1]\n",
    "        X = BertConcat() (inp)\n",
    "        X = tf.expand_dims(X, axis = -1, name ='expand_dims')\n",
    "        X = AdapterPooler(386, shared_weights = True)(X)\n",
    "        X = tf.reshape(X, (-1, X.shape[1], X.shape[2] * X.shape[3]))\n",
    "        X = tf.concat([X, inp_seq], axis = 2)\n",
    "        X = tf.squeeze(X, axis = 1)\n",
    "        X = layers.Dense(2)(X)\n",
    "        model = Model(inputs = inp, outputs = X, name = 'BinaryClassification_Adapter_Tenney')\n",
    "\n",
    "    return model\n",
    "\n",
    "model_eval = get_adapter_shared_skip_tenney_first()\n",
    "model_eval.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model <font color=\"red\">Xception Abbreviated</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xception_abbreviated(input_shape = (1, 1024, 26), gpu_device = \"/gpu:1\"):\n",
    "\n",
    "    with tf.device(gpu_device):\n",
    "\n",
    "        # input image size\n",
    "        input_img = layers.Input(shape = input_shape, dtype = tf.float32)\n",
    "\n",
    "        # Block 1\n",
    "        x = Conv2D(64, (1, 3), strides=(1, 3), use_bias=False) (input_img)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(128, (1, 3), use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        residual = Conv2D(512, (1, 1), strides=(1, 2), padding='same', use_bias=False)(x)\n",
    "        residual = BatchNormalization()(residual)\n",
    "\n",
    "        # Block 2\n",
    "        x = SeparableConv2D(256, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(512, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # Block 2 Pool\n",
    "        x = AveragePooling2D((1, 3), strides=(1, 2), padding='same')(x)\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = layers.Dense(2, dtype = tf.float32, name = 'dense_2_final') (x)\n",
    "\n",
    "        model = models.Model(input_img, x, name = 'Xception_BC')\n",
    "\n",
    "    return model\n",
    "\n",
    "model_eval = get_xception_abbreviated()\n",
    "model_eval.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model <font color=\"red\">Xception (Full)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Xception_BC\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1, 1024, 26) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 1, 341, 32)   2496        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1, 341, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1, 341, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1, 339, 64)   6144        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1, 339, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 339, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 1, 339, 128)  8384        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 339, 128)  512         separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 339, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 1, 339, 128)  16768       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, 339, 128)  512         separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 170, 128)  8192        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 170, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 170, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1, 170, 128)  0           average_pooling2d[0][0]          \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 170, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 1, 170, 256)  33152       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1, 170, 256)  1024        separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1, 170, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 1, 170, 256)  66304       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 170, 256)  1024        separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 85, 256)   32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 85, 256)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1, 85, 256)   1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1, 85, 256)   0           average_pooling2d_1[0][0]        \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1, 85, 256)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 1, 85, 728)   187136      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 85, 728)   2912        separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1, 85, 728)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 1, 85, 728)   532168      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1, 85, 728)   2912        separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1, 43, 728)   186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 43, 728)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 43, 728)   2912        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1, 43, 728)   0           average_pooling2d_2[0][0]        \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1, 43, 728)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 1, 43, 728)   532168      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 43, 728)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 1, 43, 728)   532168      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1, 43, 728)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 1, 43, 728)   532168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1, 43, 728)   0           batch_normalization_13[0][0]     \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1, 43, 728)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 1, 43, 728)   532168      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1, 43, 728)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 1, 43, 728)   532168      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1, 43, 728)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 1, 43, 728)   532168      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1, 43, 728)   0           batch_normalization_16[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, 43, 728)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 1, 43, 728)   532168      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1, 43, 728)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 1, 43, 728)   532168      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1, 43, 728)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 1, 43, 728)   532168      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1, 43, 728)   0           batch_normalization_19[0][0]     \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1, 43, 728)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 1, 43, 728)   532168      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 1, 43, 728)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 1, 43, 728)   532168      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1, 43, 728)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 1, 43, 728)   532168      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1, 43, 728)   0           batch_normalization_22[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 1, 43, 728)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 1, 43, 728)   532168      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1, 43, 728)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 1, 43, 728)   532168      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 1, 43, 728)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 1, 43, 728)   532168      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1, 43, 728)   0           batch_normalization_25[0][0]     \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1, 43, 728)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 1, 43, 728)   532168      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1, 43, 728)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 1, 43, 728)   532168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1, 43, 728)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 1, 43, 728)   532168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1, 43, 728)   0           batch_normalization_28[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1, 43, 728)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 1, 43, 728)   532168      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 1, 43, 728)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 1, 43, 728)   532168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1, 43, 728)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 1, 43, 728)   532168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1, 43, 728)   0           batch_normalization_31[0][0]     \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1, 43, 728)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 1, 43, 728)   532168      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1, 43, 728)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 1, 43, 728)   532168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1, 43, 728)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 1, 43, 728)   532168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 1, 43, 728)   0           batch_normalization_34[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1, 43, 728)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, 1, 43, 728)   532168      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1, 43, 728)   2912        separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 43, 728)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_31 (SeparableC (None, 1, 43, 1024)  747656      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1, 43, 1024)  4096        separable_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 22, 1024)  745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 22, 1024)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1, 22, 1024)  4096        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1, 22, 1024)  0           average_pooling2d_3[0][0]        \n",
      "                                                                 batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_32 (SeparableC (None, 1, 22, 1536)  1575936     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1, 22, 1536)  6144        separable_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 1, 22, 1536)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_33 (SeparableC (None, 1, 22, 2048)  3150336     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1, 22, 2048)  8192        separable_conv2d_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 1, 22, 2048)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_final (Dense)           (None, 2)            4098        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 20,716,634\n",
      "Trainable params: 20,662,106\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_xception(input_shape = (1, 1024, 26), gpu_device = \"/gpu:1\"):\n",
    "\n",
    "    with tf.device(gpu_device):\n",
    "\n",
    "        # input image size\n",
    "        input_img = layers.Input(shape = input_shape, dtype = tf.float32)\n",
    "\n",
    "        # Block 1\n",
    "        x = Conv2D(32, (1, 3), strides=(1, 3), use_bias=False) (input_img)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(64, (1, 3), use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        residual = Conv2D(128, (1, 1), strides=(1, 2), padding='same', use_bias=False)(x)\n",
    "        residual = BatchNormalization()(residual)\n",
    "\n",
    "        # Block 2\n",
    "        x = SeparableConv2D(128, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(128, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # Block 2 Pool\n",
    "        x = AveragePooling2D((1, 3), strides=(1, 2), padding='same')(x)\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "        residual = Conv2D(256, (1, 1), strides=(1, 2), padding='same', use_bias=False)(x)\n",
    "        residual = BatchNormalization()(residual)\n",
    "\n",
    "        # Block 3\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(256, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(256, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # Block 3 Pool\n",
    "        x = AveragePooling2D((1, 3), strides=(1, 2), padding='same')(x)\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "        residual = Conv2D(728, (1, 1), strides=(1, 2), padding='same', use_bias=False)(x)\n",
    "        residual = BatchNormalization()(residual)\n",
    "\n",
    "        # Block 4\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = AveragePooling2D((1, 3), strides=(1, 2), padding='same')(x)\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "        # Block 5 - 12\n",
    "        for i in range(8):\n",
    "            residual = x\n",
    "\n",
    "            x = Activation('relu')(x)\n",
    "            x = SeparableConv2D(728, (1, 3), padding='same', use_bias=False)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = SeparableConv2D(728, (1, 3), padding='same', use_bias=False)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = SeparableConv2D(728, (1, 3), padding='same', use_bias=False)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            x = layers.add([x, residual])\n",
    "\n",
    "        residual = Conv2D(1024, (1, 1), strides=(1, 2), padding='same', use_bias=False)(x)\n",
    "        residual = BatchNormalization()(residual)\n",
    "\n",
    "        # Block 13\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(1024, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # Block 13 Pool\n",
    "        x = AveragePooling2D((1, 3), strides=(1, 2), padding='same')(x)\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "        # Block 14\n",
    "        x = SeparableConv2D(1536, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        # Block 14 part 2\n",
    "        x = SeparableConv2D(2048, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "                \n",
    "        # Fully Connected Layer\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = layers.Dense(2, dtype = tf.float32, name = 'dense_2_final') (x)\n",
    "\n",
    "        model = models.Model(input_img, x, name = 'Xception_BC')\n",
    "\n",
    "    return model\n",
    "\n",
    "model_eval = get_xception()\n",
    "model_eval.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model <font color=\"red\">Xception Abbreviated CLS Residual</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xception_abbreviated_clsresidual(input_shape = (1, 1024, 26), gpu_device = \"/gpu:1\"):\n",
    "\n",
    "    with tf.device(gpu_device):\n",
    "\n",
    "        # input image size\n",
    "        input_img = layers.Input(shape = input_shape, dtype = tf.float32)\n",
    "\n",
    "        # pull the last channel layer for residual connection layer\n",
    "        inp_seq = input_img[:,:,:,-1]\n",
    "        inp_seq = tf.squeeze(inp_seq, axis = 1)\n",
    "\n",
    "        # Block 1\n",
    "        x = Conv2D(64, (1, 3), strides=(1, 3), use_bias=False) (input_img)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(128, (1, 3), use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        residual = Conv2D(512, (1, 1), strides=(1, 2), padding='same', use_bias=False)(x)\n",
    "        residual = BatchNormalization()(residual)\n",
    "\n",
    "        # Block 2\n",
    "        x = SeparableConv2D(256, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(512, (1, 3), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        # Block 2 Pool\n",
    "        x = AveragePooling2D((1, 3), strides=(1, 2), padding='same')(x)\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        # add the skip level residual back to the last CLS token\n",
    "        x = layers.concatenate([x, inp_seq])\n",
    "\n",
    "        x = layers.Dense(2, dtype = tf.float32, name = 'dense_2_final') (x)\n",
    "\n",
    "        model = models.Model(input_img, x, name = 'Xception_BC')\n",
    "\n",
    "    return model\n",
    "\n",
    "model_eval = get_xception_abbreviated_clsresidual()\n",
    "model_eval.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model <font color=\"Red\">AdapterPooling MeanAvg</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BinaryClassification_Adapter_Tenney\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        [(None, 1, 1024, 26) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mean_concat (MeanConcat)        (None, 1, 1024)      0           input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_expand_dims_23 (Ten [(None, 1, 1024, 1)] 0           mean_concat[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "adapter_pooler_23 (AdapterPoole (None, 1, 386, 1)    395650      tf_op_layer_expand_dims_23[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_23 (TensorF [(None, 1, 386)]     0           adapter_pooler_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [(None, 1, 1024)]    0           input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 1, 1410)]    0           tf_op_layer_Reshape_23[0][0]     \n",
      "                                                                 tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_21 (TensorF [(None, 1410)]       0           tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 2)            2822        tf_op_layer_Squeeze_21[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 398,472\n",
      "Trainable params: 398,472\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_adapaterpooling_meanavg(input_shape = (1, 1024, 26), gpu_device = \"/gpu:1\"):\n",
    "    \n",
    "    with tf.device(gpu_device):\n",
    "        inp = layers.Input(input_shape, name = 'input_layer')\n",
    "        inp_seq = inp[:,:,:,-1]\n",
    "        X = MeanConcat() (inp)\n",
    "        X = tf.expand_dims(X, axis = -1, name ='expand_dims')\n",
    "        X = AdapterPooler(386, shared_weights = True)(X)\n",
    "        X = tf.reshape(X, (-1, X.shape[1], X.shape[2] * X.shape[3]))\n",
    "        X = tf.concat([X, inp_seq], axis = 2)\n",
    "        X = tf.squeeze(X, axis = 1)\n",
    "        X = layers.Dense(2)(X)\n",
    "        model = Model(inputs = inp, outputs = X, name = 'BinaryClassification_Adapter_Tenney')\n",
    "\n",
    "    return model\n",
    "\n",
    "model_eval = get_adapaterpooling_meanavg()\n",
    "model_eval.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance Against DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs = 1, model_name = \"adapterpooling_tenney\", model = None):\n",
    "    \n",
    "    if (not model):\n",
    "        if model_name == \"adapterpooling_tenney\":\n",
    "            model = get_adapter_shared_skip_tenney_first()\n",
    "        elif model_name == \"xception_abbreviated\":\n",
    "            model = get_xception_abbreviated()\n",
    "        elif model_name == \"xception\":\n",
    "            model = get_xception()\n",
    "        elif model_name == \"xception_abbreviated_clsresidual\":\n",
    "            model = get_xception_abbreviated_clsresidual()\n",
    "        elif model_name == \"get_adapaterpooling_meanavg\":\n",
    "            model = get_adapaterpooling_meanavg()\n",
    "        elif model_name == \"get_tiny_tenney\":\n",
    "            model = get_tiny_tenney()\n",
    "        else:\n",
    "            raise RuntimeError(f\"no model found with name `{model_name}.\")\n",
    "    \n",
    "    opt = Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-8)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(loss = loss, optimizer = opt, metrics = ['accuracy'])\n",
    "    \n",
    "    _ = model.fit(x = train, y = answer_no_answer, epochs = epochs, \n",
    "            batch_size = 64, verbose = True, shuffle = True)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating performance for xception...\n",
      "2062/2062 [==============================] - 236s 114ms/step - loss: 0.0558 - accuracy: 0.9817\n",
      "epoch [1] f1 score: 0.777610818933133\n",
      "epoch [1] accuracy: 0.8005558830961004\n",
      "2062/2062 [==============================] - 236s 115ms/step - loss: 0.0506 - accuracy: 0.9831\n",
      "epoch [2] f1 score: 0.7862272141410421\n",
      "epoch [2] accuracy: 0.8044302198264971\n",
      "2062/2062 [==============================] - 238s 115ms/step - loss: 0.0481 - accuracy: 0.9839\n",
      "epoch [3] f1 score: 0.7872733999260082\n",
      "epoch [3] accuracy: 0.806283163480165\n",
      "2062/2062 [==============================] - 235s 114ms/step - loss: 0.0461 - accuracy: 0.9845\n",
      "epoch [4] f1 score: 0.7915402298850575\n",
      "epoch [4] accuracy: 0.809062578960667\n",
      "2062/2062 [==============================] - 214s 104ms/step - loss: 0.0441 - accuracy: 0.9851\n",
      "epoch [5] f1 score: 0.7905392968893796\n",
      "epoch [5] accuracy: 0.8083045565568938\n",
      "1919/2062 [==========================>...] - ETA: 15s - loss: 0.0425 - accuracy: 0.9855"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"xception\"\n",
    "\n",
    "print(f\"Evaluating performance for {MODEL_NAME}...\")\n",
    "results = {'epoch':[], 'f1':[], 'em':[]}\n",
    "model = None\n",
    "\n",
    "for epochs in range(10):\n",
    "    e = epochs + 1\n",
    "    \n",
    "    model = train_model(epochs = 1, model_name = MODEL_NAME, model = model)\n",
    "\n",
    "    pred = model.predict(dev)\n",
    "    pred = np.argmax(pred, axis = 1).astype(np.uint8)\n",
    "    \n",
    "    df = pd.DataFrame({'qas_id':dev_qasids, 'prediction':pred}).groupby(by='qas_id').agg({'prediction':'max'})\n",
    "    #ans = pd.DataFrame(dev_answers, index =[0]).T\n",
    "    #ans.columns = ['answer']\n",
    "    df = df.merge(dev_answers, how='inner', left_index = True, right_index = True)\n",
    "\n",
    "    f1 = f1_score(y_true = df.answer.values, y_pred = df.prediction.values)\n",
    "    em = accuracy_score(y_true = df.answer.values, y_pred = df.prediction.values)\n",
    "\n",
    "    results['epoch'].append(e)\n",
    "    results['f1'].append(f1)\n",
    "    results['em'].append(em)\n",
    "\n",
    "    print(f\"epoch [{e}] f1 score: {f1}\")\n",
    "    print(f\"epoch [{e}] accuracy: {em}\")\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the performance dictionary for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10},\n",
       " 'f1': {0: 0.794728653793356,\n",
       "  1: 0.7922723091076358,\n",
       "  2: 0.7896631287494231,\n",
       "  3: 0.7884562020164646,\n",
       "  4: 0.7869795047760363,\n",
       "  5: 0.786032689450223,\n",
       "  6: 0.7853091585309159,\n",
       "  7: 0.7853023255813953,\n",
       "  8: 0.784518049869743,\n",
       "  9: 0.7840655249441549},\n",
       " 'em': {0: 0.8110839720373958,\n",
       "  1: 0.8098206013644403,\n",
       "  2: 0.8080518824223027,\n",
       "  3: 0.8073780847300598,\n",
       "  4: 0.8065358376147562,\n",
       "  5: 0.8059462646340436,\n",
       "  6: 0.8055251410763918,\n",
       "  7: 0.8056093657879222,\n",
       "  8: 0.8049355680956792,\n",
       "  9: 0.8045986692495578}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
