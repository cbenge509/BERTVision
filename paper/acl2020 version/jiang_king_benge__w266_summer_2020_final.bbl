\begin{thebibliography}{15}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{van Aken et~al.(2019)van Aken, Winter, Löser, and
  Gers}]{van_Aken_2019}
Betty van Aken, Benjamin Winter, Alexander Löser, and Felix~A. Gers. 2019.
\newblock \href {https://doi.org/10.1145/3357384.3358028} {How does {BERT}
  answer questions?}
\newblock \emph{Proceedings of the 28th ACM International Conference on
  Information and Knowledge Management}.

\bibitem[{Chen et~al.(2020)Chen, Trabelsi, Heflin, Xu, and Davison}]{Chen_2020}
Zhiyu Chen, Mohamed Trabelsi, Jeff Heflin, Yinan Xu, and Brian~D. Davison.
  2020.
\newblock \href {https://doi.org/10.1145/3397271.3401044} {Table search using a
  deep contextualized language model}.
\newblock \emph{Proceedings of the 43rd International ACM SIGIR Conference on
  Research and Development in Information Retrieval}.

\bibitem[{Chollet(2016)}]{DBLP:journals/corr/Chollet16a}
Fran{\c{c}}ois Chollet. 2016.
\newblock \href {http://arxiv.org/abs/1610.02357} {Xception: Deep learning with
  depthwise separable convolutions}.
\newblock \emph{CoRR}, abs/1610.02357.

\bibitem[{Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova}]{Devlin2019}
Jacob Devlin, Ming~Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.
\newblock \href {http://arxiv.org/abs/1810.04805} {{BERT: Pre-training of deep
  bidirectional transformers for language understanding}}.
\newblock In \emph{NAACL HLT 2019 - 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies - Proceedings of the Conference}.

\bibitem[{Houlsby et~al.(2019)Houlsby, Giurgiu, Jastrzebski, Morrone,
  de~Laroussilhe, Gesmundo, Attariyan, and
  Gelly}]{DBLP:journals/corr/abs-1902-00751}
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin
  de~Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019.
\newblock \href {http://arxiv.org/abs/1902.00751} {Parameter-efficient transfer
  learning for {NLP}}.
\newblock \emph{CoRR}, abs/1902.00751.

\bibitem[{Ma et~al.(2019)Ma, Wang, Ng, Nallapati, and Xiang}]{ma2019universal}
Xiaofei Ma, Zhiguo Wang, Patrick Ng, Ramesh Nallapati, and Bing Xiang. 2019.
\newblock \href {http://arxiv.org/abs/1910.07973} {Universal text
  representation from {BERT}: An empirical study}.

\bibitem[{Papineni et~al.(2002)Papineni, Roukos, Ward, and jing
  Zhu}]{Papineni02bleu:a}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei jing Zhu. 2002.
\newblock {BLEU}: a method for automatic evaluation of machine translation.
\newblock pages 311--318.

\bibitem[{Rajpurkar et~al.(2018)Rajpurkar, Jia, and
  Liang}]{DBLP:journals/corr/abs-1806-03822}
Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
\newblock \href {http://arxiv.org/abs/1806.03822} {Know what you don't know:
  Unanswerable questions for {SQ}u{AD}}.
\newblock \emph{CoRR}, abs/1806.03822.

\bibitem[{Sanh et~al.(2019)Sanh, Debut, Chaumond, and
  Wolf}]{sanh2019distilbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.
\newblock \href {http://arxiv.org/abs/1910.01108} {Distil{BERT}, a distilled
  version of {BERT}: smaller, faster, cheaper and lighter}.

\bibitem[{Szegedy et~al.(2014)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich}]{DBLP:journals/corr/SzegedyLJSRAEVR14}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott~E. Reed,
  Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
  2014.
\newblock \href {http://arxiv.org/abs/1409.4842} {Going deeper with
  convolutions}.
\newblock \emph{CoRR}, abs/1409.4842.

\bibitem[{Tenney et~al.(2019{\natexlab{a}})Tenney, Das, and
  Pavlick}]{tenney-etal-2019-bert}
Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/P19-1452} {{BERT} rediscovers the
  classical {NLP} pipeline}.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 4593--4601, Florence, Italy.
  Association for Computational Linguistics.

\bibitem[{Tenney et~al.(2019{\natexlab{b}})Tenney, Xia, Chen, Wang, Poliak,
  McCoy, Kim, Durme, Bowman, Das, and
  Pavlick}]{DBLP:journals/corr/abs-1905-06316}
Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R.~Thomas McCoy,
  Najoung Kim, Benjamin~Van Durme, Samuel~R. Bowman, Dipanjan Das, and Ellie
  Pavlick. 2019{\natexlab{b}}.
\newblock \href {http://arxiv.org/abs/1905.06316} {What do you learn from
  context? {P}robing for sentence structure in contextualized word
  representations}.
\newblock \emph{CoRR}, abs/1905.06316.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{Vaswani2017}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, {\L}ukasz Kaiser, and Illia Polosukhin. 2017.
\newblock {Attention is all you need}.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Wu et~al.(2016)Wu, Schuster, Chen, Le, Norouzi, Macherey, Krikun,
  Cao, Gao, Macherey, Klingner, Shah, Johnson, Liu, Kaiser, Gouws, Kato, Kudo,
  Kazawa, Stevens, Kurian, Patil, Wang, Young, Smith, Riesa, Rudnick, Vinyals,
  Corrado, Hughes, and Dean}]{DBLP:journals/corr/WuSCLNMKCGMKSJL16}
Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc~V. Le, Mohammad Norouzi, Wolfgang
  Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner,
  Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws,
  Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian,
  Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick,
  Oriol Vinyals, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016.
\newblock \href {http://arxiv.org/abs/1609.08144} {Google's neural machine
  translation system: Bridging the gap between human and machine translation}.
\newblock \emph{CoRR}, abs/1609.08144.

\bibitem[{Zhu et~al.(2020)Zhu, Xia, Wu, He, Qin, Zhou, Li, and
  Liu}]{Zhu2020IncorporatingBI}
Jinhua Zhu, Yingce Xia, Lijun Wu, Di~He, Tao Qin, Wengang Zhou, Houqiang Li,
  and Tie-Yan Liu. 2020.
\newblock Incorporating {BERT} into neural machine translation.
\newblock \emph{ArXiv}, abs/2002.06823.

\end{thebibliography}
