{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from transformers import TFBertModel, TFBertForQuestionAnswering\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Activation, GlobalMaxPool1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import multi_gpu_model, to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from transformers.data.processors.squad import SquadV2Processor\n",
    "from transformers import BertTokenizer\n",
    "from transformers.data.processors.squad import squad_convert_examples_to_features\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "import pandas as pd\n",
    "from transformers import BertConfig\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model from Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"bert-large-uncased\", output_hidden_states = True)\n",
    "bert_layer = TFBertModel.from_pretrained('bert-large-uncased', config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_bert_model(bert_layer):\n",
    "    max_seq_length = 386\n",
    "\n",
    "    input_ids = Input((max_seq_length,), dtype = tf.int32, name = 'input_ids')\n",
    "    input_masks = Input((max_seq_length,), dtype = tf.int32, name = 'input_masks')\n",
    "    input_tokens = Input((max_seq_length,), dtype = tf.int32, name = 'input_tokens')\n",
    "\n",
    "    #1 for pooled outputs (CLS token), 0 for sequence\n",
    "    _, cls_output, embeddings = bert_layer([input_ids, input_masks, input_tokens])\n",
    "    x = Dense(2, name = 'dense_2', kernel_initializer = 'he_normal') (cls_output)\n",
    "\n",
    "    model = Model(inputs = [input_ids, input_masks, input_tokens], outputs = [x,cls_output, embeddings],\n",
    "                  name = 'BERT_SQuADv2_BinaryClassification')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base = get_base_bert_model(bert_layer)\n",
    "bert_base.load_weights('./weights/bert_squadv2_binary_classification_weights_epoch_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = h5py.File(r'C:/w266/cris/BERTVision/data/squad_train.h5', 'r')\n",
    "dev_data = h5py.File(r'C:/w266/cris/BERTVision/data/squad_dev.h5', 'r')\n",
    "indices = np.array(eval(open('indices.txt', 'r').readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 386\n",
    "\n",
    "train_ids = np.array(train_data['input_ids'], dtype = np.int32)[indices]\n",
    "train_masks = np.array(train_data['attention_mask'], dtype = np.int32)[indices]\n",
    "train_tokens = np.array(train_data['token_type_ids'], dtype = np.int32)[indices]\n",
    "\n",
    "dev_ids = np.array(dev_data['input_ids'], dtype = np.int32)\n",
    "dev_masks = np.array(dev_data['attention_mask'], dtype = np.int32)\n",
    "dev_tokens = np.array(dev_data['token_type_ids'], dtype = np.int32)\n",
    "\n",
    "train_input_start = np.array(train_data['input_start'], dtype = np.int32)[indices]\n",
    "train_input_end = np.array(train_data['input_end'], dtype = np.int32)[indices]\n",
    "\n",
    "answer_no_answer = np.where(train_input_start + train_input_end > 0, 0, 1)\n",
    "answer_no_answer = to_categorical(answer_no_answer).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:04<00:00,  7.17it/s]\n",
      "convert squad examples to features: 100%|███████████████████████████████████████| 11873/11873 [01:47<00:00, 110.20it/s]\n",
      "add example index and unique id: 100%|███████████████████████████████████████| 11873/11873 [00:00<00:00, 379851.96it/s]\n"
     ]
    }
   ],
   "source": [
    "processor = SquadV2Processor()\n",
    "data_raw = processor.get_dev_examples(\"C:/w266/cris/BERTVision/data\")\n",
    "\n",
    "dev_answers = dict(zip([d.qas_id for d in data_raw], \n",
    "    [np.uint8(d.is_impossible) for d in data_raw]))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "dd_raw = squad_convert_examples_to_features(\n",
    "            examples = data_raw,\n",
    "            tokenizer = tokenizer,\n",
    "            max_seq_length = 386,\n",
    "            doc_stride = 128,\n",
    "            max_query_length = 64,\n",
    "            is_training = False,)\n",
    "\n",
    "dev_predict_qasids = [d.qas_id for d in dd_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings for Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0546ec50aa844c7295fe3e50ffd4229b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev embeddings saved to './data/dev_embeddings_3_epoch.pkl' with shape: (12227, 1024, 26)\n"
     ]
    }
   ],
   "source": [
    "data = np.zeros((len(dev_ids), 1024, 26), dtype = np.float16)\n",
    "\n",
    "for i in tqdm(range(len(dev_ids))):\n",
    "    _, cls_output, embeddings = bert_base.predict([dev_ids[[i]], dev_masks[[i]], dev_tokens[[i]]])\n",
    "    data[i] = np.concatenate([np.expand_dims(cls_output, axis=2), \n",
    "                              np.transpose(np.array(embeddings), (1,2,3,0))[:,0,::]], axis=2)\n",
    "\n",
    "with open('./data/dev_embeddings_3_epoch.pkl', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"dev embeddings saved to './data/dev_embeddings_3_epoch.pkl' with shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d968170d3d7440d6858c4b14cc4550a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=131911.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train embeddings saved to './data/train_embeddings_3_epoch.pkl' with shape: (131911, 1024, 26)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.zeros((len(train_ids), 1024, 26), dtype = np.float16)\n",
    "\n",
    "for i in tqdm(range(len(train_ids))):\n",
    "    _, cls_output, embeddings = bert_base.predict([train_ids[[i]], train_masks[[i]], train_tokens[[i]]])\n",
    "    train_data[i] = np.concatenate([np.expand_dims(cls_output, axis=2), \n",
    "                              np.transpose(np.array(embeddings), (1,2,3,0))[:,0,::]], axis=2)\n",
    "\n",
    "with open('./data/train_embeddings_3_epoch.pkl', 'wb') as handle:\n",
    "    pickle.dump(train_data, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"train embeddings saved to './data/train_embeddings_3_epoch.pkl' with shape: {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
